"""
Monitoring Components for AI Usage Tracking
Technical implementations for different monitoring scenarios
"""

import json
import requests
import pandas as pd
import sqlite3
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import hashlib
import re

class DeveloperAIMonitor:
    """Monitors developer AI tool usage across IDEs and coding platforms"""
    
    def __init__(self, db_path: str = "ai_usage.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialize SQLite database for tracking"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Developer AI usage table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS developer_ai_usage (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                tool_name TEXT NOT NULL,
                session_start TIMESTAMP,
                session_end TIMESTAMP,
                suggestions_accepted INTEGER DEFAULT 0,
                suggestions_rejected INTEGER DEFAULT 0,
                lines_generated INTEGER DEFAULT 0,
                code_quality_score REAL,
                security_issues INTEGER DEFAULT 0,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Code analysis table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS code_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                file_path TEXT,
                ai_generated_percentage REAL,
                complexity_score REAL,
                security_score REAL,
                maintainability_score REAL,
                ai_tool_used TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def track_github_copilot_usage(self, user_id: str, telemetry_data: Dict) -> Dict:
        """Track GitHub Copilot usage from telemetry"""
        usage_data = {
            'user_id': user_id,
            'tool_name': 'GitHub Copilot',
            'session_start': telemetry_data.get('session_start'),
            'session_end': telemetry_data.get('session_end'),
            'suggestions_accepted': telemetry_data.get('acceptances', 0),
            'suggestions_rejected': telemetry_data.get('rejections', 0),
            'lines_generated': telemetry_data.get('lines_suggested', 0)
        }
        
        # Store in database
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO developer_ai_usage 
            (user_id, tool_name, session_start, session_end, suggestions_accepted, 
             suggestions_rejected, lines_generated)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            usage_data['user_id'], usage_data['tool_name'], 
            usage_data['session_start'], usage_data['session_end'],
            usage_data['suggestions_accepted'], usage_data['suggestions_rejected'],
            usage_data['lines_generated']
        ))
        
        conn.commit()
        conn.close()
        
        return usage_data
    
    def analyze_code_quality(self, user_id: str, code_content: str, file_path: str) -> Dict:
        """Analyze code quality and detect AI-generated patterns"""
        
        # Detect AI-generated code patterns
        ai_patterns = [
            r'# Generated by AI',
            r'// AI-generated',
            r'""".*AI.*generated.*"""',
            r'# This code was created with assistance from',
            # Common AI code patterns
            r'def\s+\w+\(\s*\)\s*:\s*pass',  # Empty functions
            r'# TODO:.*implement',  # Common AI placeholders
        ]
        
        ai_generated_lines = 0
        total_lines = len(code_content.split('\n'))
        
        for pattern in ai_patterns:
            matches = re.findall(pattern, code_content, re.IGNORECASE | re.MULTILINE)
            ai_generated_lines += len(matches)
        
        ai_percentage = (ai_generated_lines / total_lines) * 100 if total_lines > 0 else 0
        
        # Simple complexity analysis
        complexity_indicators = [
            len(re.findall(r'\bif\b', code_content)),
            len(re.findall(r'\bfor\b', code_content)),
            len(re.findall(r'\bwhile\b', code_content)),
            len(re.findall(r'\btry\b', code_content))
        ]
        complexity_score = sum(complexity_indicators) / total_lines if total_lines > 0 else 0
        
        # Security analysis (basic)
        security_issues = [
            len(re.findall(r'eval\(', code_content)),
            len(re.findall(r'exec\(', code_content)),
            len(re.findall(r'input\(', code_content)),
            len(re.findall(r'os\.system', code_content))
        ]
        security_score = 10 - sum(security_issues)  # Higher is better
        
        analysis = {
            'user_id': user_id,
            'file_path': file_path,
            'ai_generated_percentage': ai_percentage,
            'complexity_score': complexity_score,
            'security_score': max(0, security_score),
            'maintainability_score': 10 - complexity_score,  # Inverse of complexity
            'total_lines': total_lines
        }
        
        # Store analysis
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO code_analysis 
            (user_id, file_path, ai_generated_percentage, complexity_score, 
             security_score, maintainability_score)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            analysis['user_id'], analysis['file_path'],
            analysis['ai_generated_percentage'], analysis['complexity_score'],
            analysis['security_score'], analysis['maintainability_score']
        ))
        
        conn.commit()
        conn.close()
        
        return analysis
    
    def get_developer_productivity_metrics(self, user_id: str, days: int = 30) -> Dict:
        """Get productivity metrics for a developer"""
        conn = sqlite3.connect(self.db_path)
        
        # Get usage data
        usage_df = pd.read_sql_query('''
            SELECT * FROM developer_ai_usage 
            WHERE user_id = ? AND timestamp >= datetime('now', '-{} days')
        '''.format(days), conn, params=(user_id,))
        
        # Get code analysis data
        analysis_df = pd.read_sql_query('''
            SELECT * FROM code_analysis 
            WHERE user_id = ? AND timestamp >= datetime('now', '-{} days')
        '''.format(days), conn, params=(user_id,))
        
        conn.close()
        
        metrics = {
            'user_id': user_id,
            'period_days': days,
            'total_sessions': len(usage_df),
            'total_suggestions_accepted': usage_df['suggestions_accepted'].sum(),
            'total_suggestions_rejected': usage_df['suggestions_rejected'].sum(),
            'acceptance_rate': (usage_df['suggestions_accepted'].sum() / 
                              (usage_df['suggestions_accepted'].sum() + usage_df['suggestions_rejected'].sum())
                              if (usage_df['suggestions_accepted'].sum() + usage_df['suggestions_rejected'].sum()) > 0 else 0),
            'total_lines_generated': usage_df['lines_generated'].sum(),
            'avg_ai_code_percentage': analysis_df['ai_generated_percentage'].mean() if len(analysis_df) > 0 else 0,
            'avg_code_quality': analysis_df['security_score'].mean() if len(analysis_df) > 0 else 0,
            'files_analyzed': len(analysis_df)
        }
        
        return metrics

class BusinessUserAIMonitor:
    """Monitors business user AI tool usage across productivity applications"""
    
    def __init__(self, db_path: str = "ai_usage.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialize database for business user tracking"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS business_ai_usage (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                tool_name TEXT NOT NULL,
                activity_type TEXT,
                session_duration INTEGER,
                content_generated INTEGER DEFAULT 0,
                data_processed INTEGER DEFAULT 0,
                cost_incurred REAL DEFAULT 0.0,
                department TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS content_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                content_type TEXT,
                content_hash TEXT,
                ai_confidence_score REAL,
                sensitive_data_detected BOOLEAN DEFAULT FALSE,
                compliance_risk_level TEXT,
                tool_used TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def track_office365_copilot_usage(self, user_data: Dict) -> Dict:
        """Track Microsoft 365 Copilot usage"""
        usage_data = {
            'user_id': user_data['user_id'],
            'tool_name': 'Microsoft 365 Copilot',
            'activity_type': user_data.get('activity_type', 'general'),
            'session_duration': user_data.get('session_duration_minutes', 0),
            'content_generated': user_data.get('documents_created', 0),
            'department': user_data.get('department', 'unknown')
        }
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO business_ai_usage 
            (user_id, tool_name, activity_type, session_duration, content_generated, department)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            usage_data['user_id'], usage_data['tool_name'],
            usage_data['activity_type'], usage_data['session_duration'],
            usage_data['content_generated'], usage_data['department']
        ))
        
        conn.commit()
        conn.close()
        
        return usage_data
    
    def analyze_content_for_sensitive_data(self, user_id: str, content: str, content_type: str) -> Dict:
        """Analyze content for sensitive data and compliance risks"""
        
        # Create content hash for tracking without storing actual content
        content_hash = hashlib.sha256(content.encode()).hexdigest()[:16]
        
        # Detect sensitive data patterns
        sensitive_patterns = {
            'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
            'credit_card': r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
            'ip_address': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
        }
        
        detected_types = []
        for data_type, pattern in sensitive_patterns.items():
            if re.search(pattern, content):
                detected_types.append(data_type)
        
        # Determine compliance risk level
        if any(t in ['ssn', 'credit_card'] for t in detected_types):
            risk_level = 'HIGH'
        elif any(t in ['email', 'phone'] for t in detected_types):
            risk_level = 'MEDIUM'
        elif detected_types:
            risk_level = 'LOW'
        else:
            risk_level = 'NONE'
        
        # AI confidence score (simplified)
        ai_indicators = [
            'generated by ai', 'ai-generated', 'created with assistance',
            'chatgpt', 'claude', 'copilot', 'artificial intelligence'
        ]
        
        ai_score = sum(1 for indicator in ai_indicators if indicator in content.lower())
        ai_confidence = min(ai_score * 0.2, 1.0)  # Scale to 0-1
        
        analysis = {
            'user_id': user_id,
            'content_type': content_type,
            'content_hash': content_hash,
            'ai_confidence_score': ai_confidence,
            'sensitive_data_detected': len(detected_types) > 0,
            'compliance_risk_level': risk_level,
            'detected_data_types': detected_types
        }
        
        # Store analysis
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO content_analysis 
            (user_id, content_type, content_hash, ai_confidence_score, 
             sensitive_data_detected, compliance_risk_level)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            analysis['user_id'], analysis['content_type'], analysis['content_hash'],
            analysis['ai_confidence_score'], analysis['sensitive_data_detected'],
            analysis['compliance_risk_level']
        ))
        
        conn.commit()
        conn.close()
        
        return analysis
    
    def get_department_usage_summary(self, department: str, days: int = 30) -> Dict:
        """Get AI usage summary for a department"""
        conn = sqlite3.connect(self.db_path)
        
        usage_df = pd.read_sql_query('''
            SELECT * FROM business_ai_usage 
            WHERE department = ? AND timestamp >= datetime('now', '-{} days')
        '''.format(days), conn, params=(department,))
        
        content_df = pd.read_sql_query('''
            SELECT ca.* FROM content_analysis ca
            JOIN business_ai_usage bau ON ca.user_id = bau.user_id
            WHERE bau.department = ? AND ca.timestamp >= datetime('now', '-{} days')
        '''.format(days), conn, params=(department,))
        
        conn.close()
        
        summary = {
            'department': department,
            'period_days': days,
            'unique_users': usage_df['user_id'].nunique(),
            'total_sessions': len(usage_df),
            'total_session_time': usage_df['session_duration'].sum(),
            'avg_session_time': usage_df['session_duration'].mean() if len(usage_df) > 0 else 0,
            'content_items_created': usage_df['content_generated'].sum(),
            'high_risk_content': len(content_df[content_df['compliance_risk_level'] == 'HIGH']),
            'sensitive_data_incidents': len(content_df[content_df['sensitive_data_detected'] == True]),
            'most_used_tools': usage_df['tool_name'].value_counts().to_dict()
        }
        
        return summary

class NetworkAITrafficMonitor:
    """Monitors AI tool usage through network traffic analysis"""
    
    def __init__(self):
        self.ai_domains = [
            'api.openai.com', 'claude.ai', 'bard.google.com',
            'copilot.microsoft.com', 'github.com/copilot',
            'api.anthropic.com', 'gemini.google.com'
        ]
    
    def analyze_network_logs(self, log_file: str) -> List[Dict]:
        """Analyze network logs for AI service usage"""
        ai_traffic = []
        
        with open(log_file, 'r') as f:
            for line in f:
                # Parse log line (format may vary)
                # Example: timestamp, source_ip, destination, bytes_sent, bytes_received
                parts = line.strip().split(',')
                if len(parts) >= 5:
                    timestamp, source_ip, destination, bytes_sent, bytes_received = parts[:5]
                    
                    # Check if destination is an AI service
                    for domain in self.ai_domains:
                        if domain in destination:
                            ai_traffic.append({
                                'timestamp': timestamp,
                                'source_ip': source_ip,
                                'ai_service': domain,
                                'bytes_sent': int(bytes_sent),
                                'bytes_received': int(bytes_received),
                                'session_size': int(bytes_sent) + int(bytes_received)
                            })
                            break
        
        return ai_traffic
    
    def detect_shadow_ai_usage(self, network_data: List[Dict]) -> List[Dict]:
        """Detect unauthorized AI tool usage"""
        # Group by source IP and AI service
        usage_by_ip = {}
        
        for entry in network_data:
            ip = entry['source_ip']
            service = entry['ai_service']
            
            if ip not in usage_by_ip:
                usage_by_ip[ip] = {}
            
            if service not in usage_by_ip[ip]:
                usage_by_ip[ip][service] = {
                    'sessions': 0,
                    'total_bytes': 0,
                    'first_seen': entry['timestamp'],
                    'last_seen': entry['timestamp']
                }
            
            usage_by_ip[ip][service]['sessions'] += 1
            usage_by_ip[ip][service]['total_bytes'] += entry['session_size']
            usage_by_ip[ip][service]['last_seen'] = entry['timestamp']
        
        # Identify potential shadow usage (high volume, frequent access)
        shadow_usage = []
        for ip, services in usage_by_ip.items():
            for service, stats in services.items():
                if stats['sessions'] > 100 or stats['total_bytes'] > 1000000:  # Thresholds
                    shadow_usage.append({
                        'source_ip': ip,
                        'ai_service': service,
                        'risk_level': 'HIGH' if stats['sessions'] > 500 else 'MEDIUM',
                        'sessions': stats['sessions'],
                        'total_bytes': stats['total_bytes'],
                        'duration_days': (datetime.fromisoformat(stats['last_seen']) - 
                                        datetime.fromisoformat(stats['first_seen'])).days
                    })
        
        return shadow_usage

class ComplianceReporter:
    """Generates compliance reports for AI usage"""
    
    def __init__(self, db_path: str = "ai_usage.db"):
        self.db_path = db_path
    
    def generate_gdpr_compliance_report(self, start_date: str, end_date: str) -> Dict:
        """Generate GDPR compliance report"""
        conn = sqlite3.connect(self.db_path)
        
        # Get high-risk content incidents
        high_risk_df = pd.read_sql_query('''
            SELECT user_id, content_type, compliance_risk_level, timestamp
            FROM content_analysis 
            WHERE compliance_risk_level IN ('HIGH', 'MEDIUM')
            AND timestamp BETWEEN ? AND ?
        ''', conn, params=(start_date, end_date))
        
        # Get sensitive data incidents
        sensitive_df = pd.read_sql_query('''
            SELECT user_id, content_type, timestamp
            FROM content_analysis 
            WHERE sensitive_data_detected = TRUE
            AND timestamp BETWEEN ? AND ?
        ''', conn, params=(start_date, end_date))
        
        conn.close()
        
        report = {
            'report_period': f"{start_date} to {end_date}",
            'total_high_risk_incidents': len(high_risk_df[high_risk_df['compliance_risk_level'] == 'HIGH']),
            'total_medium_risk_incidents': len(high_risk_df[high_risk_df['compliance_risk_level'] == 'MEDIUM']),
            'sensitive_data_incidents': len(sensitive_df),
            'affected_users': high_risk_df['user_id'].nunique(),
            'incidents_by_content_type': high_risk_df['content_type'].value_counts().to_dict(),
            'recommendations': [
                'Implement additional training for users with high-risk incidents',
                'Review and update AI usage policies',
                'Consider implementing DLP controls for AI tools',
                'Conduct regular compliance audits'
            ]
        }
        
        return report
    
    def generate_executive_dashboard_data(self) -> Dict:
        """Generate executive dashboard data"""
        conn = sqlite3.connect(self.db_path)
        
        # Get overall usage statistics
        dev_usage = pd.read_sql_query('''
            SELECT COUNT(*) as sessions, SUM(lines_generated) as lines_generated
            FROM developer_ai_usage 
            WHERE timestamp >= datetime('now', '-30 days')
        ''', conn)
        
        business_usage = pd.read_sql_query('''
            SELECT COUNT(*) as sessions, SUM(session_duration) as total_time
            FROM business_ai_usage 
            WHERE timestamp >= datetime('now', '-30 days')
        ''', conn)
        
        compliance_issues = pd.read_sql_query('''
            SELECT compliance_risk_level, COUNT(*) as count
            FROM content_analysis 
            WHERE timestamp >= datetime('now', '-30 days')
            GROUP BY compliance_risk_level
        ''', conn)
        
        conn.close()
        
        dashboard = {
            'period': 'Last 30 Days',
            'developer_metrics': {
                'total_sessions': dev_usage.iloc[0]['sessions'] if len(dev_usage) > 0 else 0,
                'lines_generated': dev_usage.iloc[0]['lines_generated'] if len(dev_usage) > 0 else 0
            },
            'business_metrics': {
                'total_sessions': business_usage.iloc[0]['sessions'] if len(business_usage) > 0 else 0,
                'total_hours': (business_usage.iloc[0]['total_time'] / 60) if len(business_usage) > 0 else 0
            },
            'compliance_summary': compliance_issues.set_index('compliance_risk_level')['count'].to_dict(),
            'overall_health': 'GREEN'  # Would be calculated based on thresholds
        }
        
        return dashboard

# Usage Examples
if __name__ == "__main__":
    # Initialize monitors
    dev_monitor = DeveloperAIMonitor()
    business_monitor = BusinessUserAIMonitor()
    network_monitor = NetworkAITrafficMonitor()
    compliance_reporter = ComplianceReporter()
    
    # Example: Track GitHub Copilot usage
    copilot_data = {
        'session_start': '2024-01-03 09:00:00',
        'session_end': '2024-01-03 17:00:00',
        'acceptances': 45,
        'rejections': 12,
        'lines_suggested': 230
    }
    dev_monitor.track_github_copilot_usage('dev001', copilot_data)
    
    # Example: Analyze business user content
    sample_content = "This document was created with AI assistance to analyze quarterly sales data including customer emails and phone numbers."
    business_monitor.analyze_content_for_sensitive_data('user001', sample_content, 'document')
    
    # Example: Generate compliance report
    report = compliance_reporter.generate_gdpr_compliance_report('2024-01-01', '2024-01-31')
    print(json.dumps(report, indent=2))